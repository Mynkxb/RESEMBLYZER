{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_toolbox_collab_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mynkxb/RESEMBLYZER/blob/master/demo_toolbox_collab_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yk3PMfBuZhS"
      },
      "source": [
        "Make sure GPU is enabled\n",
        "Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhunyJSod_UT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccdf825-13c6-4d1c-ffbc-6d89e0614664"
      },
      "source": [
        "# Clone git repo\n",
        "!git clone https://github.com/CorentinJ/Real-Time-Voice-Cloning.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Real-Time-Voice-Cloning'...\n",
            "remote: Enumerating objects: 2582, done.\u001b[K\n",
            "remote: Total 2582 (delta 0), reused 0 (delta 0), pack-reused 2582\u001b[K\n",
            "Receiving objects: 100% (2582/2582), 360.93 MiB | 32.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1424/1424), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GneTTDCIs8TM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c73bc0c-28aa-4f42-aa77-1c5953426503"
      },
      "source": [
        "cd Real-Time-Voice-Cloning/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Real-Time-Voice-Cloning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AVd9vLKeKm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce2ca38-77d1-4dc9-df66-693a0e4e08c0"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt\n",
        "!apt-get install -qq libportaudio2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 3.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.5MB 318kB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 42.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.3MB 49.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.9MB 64kB/s \n",
            "\u001b[K     |████████████████████████████████| 286kB 59.9MB/s \n",
            "\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuwgOQlPeN8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4649fb20-a129-4d96-8452-a632acde30f0"
      },
      "source": [
        "# Download dataset\n",
        "!gdown https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc\n",
        "!unzip pretrained.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc\n",
            "To: /content/Real-Time-Voice-Cloning/pretrained.zip\n",
            "384MB [00:04, 95.6MB/s]\n",
            "Archive:  pretrained.zip\n",
            "   creating: encoder/saved_models/\n",
            "  inflating: encoder/saved_models/pretrained.pt  \n",
            "   creating: synthesizer/saved_models/\n",
            "   creating: synthesizer/saved_models/logs-pretrained/\n",
            "   creating: synthesizer/saved_models/logs-pretrained/taco_pretrained/\n",
            " extracting: synthesizer/saved_models/logs-pretrained/taco_pretrained/checkpoint  \n",
            "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.data-00000-of-00001  \n",
            "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.index  \n",
            "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.meta  \n",
            "   creating: vocoder/saved_models/\n",
            "   creating: vocoder/saved_models/pretrained/\n",
            "  inflating: vocoder/saved_models/pretrained/pretrained.pt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53CWMIQ-eZ-L"
      },
      "source": [
        "# Code for recording audio from the browser\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "\n",
        "\n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "\n",
        "  def _repr_html_(self):\n",
        "    from google.colab import output\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "\n",
        "    template = \"\"\"<button id=\"{callback_id}\" style=\"cursor:pointer;background-color:#EEEEEE;border-color:#E0E0E0;padding:5px 15px;font-size:14px\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id)\n",
        "    return html\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  with open('audio.wav','wb+') as f:\n",
        "    f.write(b)\n",
        "  return 'audio.wav'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eIDhX0JeWQV"
      },
      "source": [
        "# !pip install -q matplotlib-venn\n",
        "# !apt-get -qq install -y libfluidsynth1\n",
        "\n",
        "# # # To determine which version you're using:\n",
        "# # !pip show tensorflow\n",
        "# # # For the current version: \n",
        "# # !pip install --upgrade tensorflow\n",
        "# # # For a specific version:\n",
        "# # !pip install tensorflow==1.2\n",
        "\n",
        "# # https://pypi.python.org/pypi/libarchive\n",
        "# !apt-get -qq install -y libarchive-dev && pip install -q -U libarchive\n",
        "# import libarchive\n",
        "\n",
        "# # https://pypi.python.org/pypi/pydot\n",
        "# !apt-get -qq install -y graphviz && pip install -q pydot\n",
        "# import pydot\n",
        "\n",
        "# !apt-get -qq install python-cartopy python3-cartopy\n",
        "# import cartopy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN_KA4_Beo0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea67f52b-1d85-432c-86a3-28da2900bc28"
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "# # For the current version: \n",
        "# !pip install --upgrade tensorflow\n",
        "# For a specific version:\n",
        "# !pip install tensorflow==1.2\n",
        "# !pip install tensorflow==1.15.0\n",
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.4.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: opt-einsum, keras-preprocessing, typing-extensions, tensorboard, h5py, grpcio, numpy, wheel, astunparse, wrapt, six, gast, protobuf, flatbuffers, tensorflow-estimator, termcolor, absl-py, google-pasta\n",
            "Required-by: fancyimpute\n",
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 97kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDvZn-k9t3Eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883dc939-3e45-4b88-9707-ee9ebd34a35d"
      },
      "source": [
        "!pip install unidecode \n",
        "!pip install webrtcvad\n",
        "from IPython.display import Audio\n",
        "from IPython.utils import io\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "encoder_weights = Path(\"encoder/saved_models/pretrained.pt\")\n",
        "vocoder_weights = Path(\"vocoder/saved_models/pretrained/pretrained.pt\")\n",
        "syn_dir = Path(\"synthesizer/saved_models/logs-pretrained/taco_pretrained\")\n",
        "encoder.load_model(encoder_weights)\n",
        "synthesizer = Synthesizer(syn_dir)\n",
        "vocoder.load_model(vocoder_weights)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.7/dist-packages (2.0.10)\n",
            "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Synthesizer using device: cpu\n",
            "Building Wave-RNN\n",
            "Trainable Parameters: 4.481M\n",
            "Loading model weights at vocoder/saved_models/pretrained/pretrained.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyLdbUfks2lv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "834742a4-19b8-4a12-8a2e-f90f65cdb814"
      },
      "source": [
        "#@title Deep vocoder\n",
        "def synth():\n",
        "  text = \"wow this project works\" #@param {type:\"string\"}\n",
        "  print(\"Now recording for 10 seconds, say what you will...\")\n",
        "  \n",
        "  ### record\n",
        "  record(30)\n",
        "  print(\"Audio recording complete\")\n",
        "  in_fpath = Path(\"audio.wav\")\n",
        "  reprocessed_wav = encoder.preprocess_wav(in_fpath)\n",
        "  original_wav, sampling_rate = librosa.load(in_fpath)\n",
        "  preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
        "  embed = encoder.embed_utterance(preprocessed_wav)\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  with io.capture_output() as captured:\n",
        "    specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate))\n",
        "InvokeButton('Start recording', synth)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button id=\"button-32d747f2-ea24-43dd-bc69-21b223882828\" style=\"cursor:pointer;background-color:#EEEEEE;border-color:#E0E0E0;padding:5px 15px;font-size:14px\">Start recording</button>\n",
              "        <script>\n",
              "          document.querySelector(\"#button-32d747f2-ea24-43dd-bc69-21b223882828\").onclick = (e) => {\n",
              "            google.colab.kernel.invokeFunction('button-32d747f2-ea24-43dd-bc69-21b223882828', [], {})\n",
              "            e.preventDefault();\n",
              "          };\n",
              "        </script>"
            ],
            "text/plain": [
              "<__main__.InvokeButton at 0x7f96546f6f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "text": [
            "Now recording for 10 seconds, say what you will...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Audio recording complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Synthesizing new audio...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}